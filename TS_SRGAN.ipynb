{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom scipy.integrate import solve_ivp\nimport matplotlib.pyplot as plt\nimport math\nimport seaborn as sns\nsns.set()\nfrom mpl_toolkits import mplot3d\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-04-07T15:48:40.554943Z","iopub.execute_input":"2024-04-07T15:48:40.555402Z","iopub.status.idle":"2024-04-07T15:48:40.562696Z","shell.execute_reply.started":"2024-04-07T15:48:40.555365Z","shell.execute_reply":"2024-04-07T15:48:40.561569Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#architecture\n\nclass Generator_net(nn.Module):\n    def __init__(self, upscale_factor, num_blocks):\n        super(Generator_net, self).__init__()\n\n        \n        self.conv1 = nn.Sequential(nn.Conv1d(3,64, kernel_size = 9, stride = 1, padding = 4),\n                                        nn.PReLU())\n        blocks = []\n        for _ in range(num_blocks):\n            blocks.append(SRResNet(64))\n\n        self.blocks = nn.Sequential(*blocks)\n\n        self.conv2 = nn.Sequential(nn.Conv1d(64,64, kernel_size = 3, stride = 1, padding = 1),\n                                              nn.BatchNorm1d(64))\n        self.conv3 = nn.Sequential(nn.Conv1d(128,64, kernel_size = 3, stride = 1, padding = 1),\n                                              nn.BatchNorm1d(64),nn.PReLU())\n        self.conv4 = nn.Sequential(nn.Conv1d(64,3 ,kernel_size = 9, stride = 1, padding = 4))\n        dummy = math.log2(upscale_factor)\n        k = int(dummy)\n        \n        dense_layer = []\n        for _ in range(k):\n            dense_layer += [\n              nn.Conv1d(64, 128, 3, 1, 1),\n              nn.BatchNorm1d(128),\n              None,\n              nn.PReLU(),\n\n            ]\n\n        self.dense_layer = nn.Sequential(*dense_layer)\n\n\n\n\n    def pixelShuffle1D(self,input,r):\n        #print(\"PS input shape: \", input.shape)\n        batch_size, channel, length = input.shape\n        channels_out = channel // r\n        new_length = length * r\n        input_view = input.view(batch_size, channels_out, r, length)\n        output = input_view.permute(0, 1, 3, 2).contiguous()\n        output = output.view(batch_size, channels_out, new_length)\n        #print(\"PS output shape: \", output.shape)\n        return output\n\n    def forward(self, vec):\n        x1 = self.conv1(vec)\n        #print(\"After conv1 layer: \", x.shape)\n        x = self.blocks(x1)\n        #print(\"After block layer: \", x.shape)\n        x2 = self.conv2(x)\n        x = torch.add(x1,x2) #skip connection\n        #print(\"After conv2 layer: \", x.shape)\n        for i,layer in enumerate(self.dense_layer):\n            if layer is None:\n                x = self.pixelShuffle1D(x,r=2)  # Custom pixel shuffle operation\n                #print(f\"After dense layer {i}: \", x.shape)\n            else:\n                x = layer(x)\n      \n        output = self.conv4(x)\n        #print(\"After conv3 layer: \", output.shape)\n        return output\n\n\n\nclass Discriminator(nn.Module):\n    def __init__(self, input_shape):\n        super(Discriminator, self).__init__()\n\n        in_filters = 3  # initial number of filters\n        layers = []\n        for i, out_filters in enumerate([64, 128, 256, 512]):\n            layers.extend(self.discriminator_block(in_filters, out_filters, first_block=(i == 0)))\n            #print(out_filters)\n            in_filters = out_filters\n\n        layers.append(nn.Conv1d(out_filters, 1, kernel_size=3, stride=1, padding = 1))\n\n        self.model = nn.Sequential(*layers)\n\n    def discriminator_block(self, in_filters, out_filters, first_block=False):\n        layers = []\n        layers.append(nn.Conv1d(in_filters, out_filters, kernel_size=3, stride=1, padding = 1))\n        if not first_block:\n            layers.append(nn.BatchNorm1d(out_filters))\n        layers.append(nn.LeakyReLU(0.2, inplace=True))\n        layers.append(nn.Conv1d(out_filters, out_filters, kernel_size=3))\n        layers.append(nn.BatchNorm1d(out_filters))\n        layers.append(nn.LeakyReLU(0.2, inplace=True))\n        return layers\n\n    def forward(self, data):\n        output = self.model(data)\n        return output\n\n      \n\n\nclass SRResNet(nn.Module):\n  def __init__(self, feature_num):\n    super(SRResNet, self).__init__()\n    self.convolutional_block = nn.Sequential(\n        nn.Conv1d(feature_num, feature_num, kernel_size = 3, stride = 1, padding = 1),\n        nn.BatchNorm1d(feature_num, 0.1),\n        nn.PReLU(),\n        nn.Conv1d(feature_num, feature_num, kernel_size = 3, stride = 1, padding = 1),\n        nn.BatchNorm1d(feature_num, 0.1),\n    )\n\n  def forward(self,x):\n      return self.convolutional_block(x) + x\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T15:48:40.564736Z","iopub.execute_input":"2024-04-07T15:48:40.565241Z","iopub.status.idle":"2024-04-07T15:48:40.588847Z","shell.execute_reply.started":"2024-04-07T15:48:40.565210Z","shell.execute_reply":"2024-04-07T15:48:40.587840Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#loss\n\ndef loss_function_mse(generated, real):\n  mse_loss = nn.MSELoss()\n  loss = mse_loss(generated, real)\n  return loss\n\n \n# def weighted_mse_loss(input, target, weights):\n  \n#     out = (input - target)**2\n#     #print(out.shape) = torch.Size([20, 3, 800])\n#     out = out * weights.expand_as(out) #same dimensionality\n#     loss = out.mean() \n#     return loss\n\n# def loss_function_mse(generated, real, start_weight=5, end_weight=1):\n#     #print(generated.shape)\n#     sequence_length = generated.size(2)\n#     penalty_length = int(sequence_length * 0.25)\n#     penalty = 5\n#     normal_weight = 1\n#     #print(sequence_length)\n#     #weights = torch.linspace(start_weight, end_weight, steps=sequence_length)\n#     first_weights = torch.full((penalty_length,), penalty)\n#     rest_weights =  torch.full((sequence_length - penalty_length,), normal_weight)\n    \n#     weights = torch.cat((first_weights, rest_weights), dim=0)\n    \n#     if generated.is_cuda:\n#         weights = weights.to(generated.device)\n    \n#     mse_loss = weighted_mse_loss(generated, real, weights)\n#     return mse_loss\n    \n\ndef loss_function_adv(output, target):\n  loss = F.binary_cross_entropy_with_logits(output, target) # or nn.BCEWithLogitsLoss()\n  return loss\n\ndef loss_L1(input,target):\n    loss = nn.L1Loss()\n    output = loss(input,target)\n    return output","metadata":{"execution":{"iopub.status.busy":"2024-04-07T15:48:40.590857Z","iopub.execute_input":"2024-04-07T15:48:40.591503Z","iopub.status.idle":"2024-04-07T15:48:40.604930Z","shell.execute_reply.started":"2024-04-07T15:48:40.591468Z","shell.execute_reply":"2024-04-07T15:48:40.604133Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#low-resolution training data(temporal):\n\ndef downsample_data(data, downsample_factor):\n    return data[:, ::downsample_factor]\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T15:48:40.606107Z","iopub.execute_input":"2024-04-07T15:48:40.606494Z","iopub.status.idle":"2024-04-07T15:48:40.619063Z","shell.execute_reply.started":"2024-04-07T15:48:40.606435Z","shell.execute_reply":"2024-04-07T15:48:40.618330Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#generating data\n\n\n\ndef my_lorenz_system(t,vec,sigma,p,beta):\n    x,y,z = vec\n    dxdt = sigma*(y-x)\n    dydt = x*(p-z)-y\n    dzdt = x*y-beta*z\n    return dxdt,dydt,dzdt\n\n\nx0_center, y0_center, z0_center = 2, 3, -14\n# number of timepoints in the trajectories:\namount_val = 800\n#amount_val = 4000\n# time interval:\nt_span = (0,7) \n#t_span = (0,100)\n\ndef generating_sample_data(num_samples,ds_factor):\n  data_hr = []\n  data_lr = []\n  radius = 0.1\n\n  for _ in range(num_samples):\n\n      #parameters\n      sigma = 10\n      beta = 8/3\n      p = 28\n\n      t_eval = np.linspace(t_span[0], t_span[1], amount_val) #array of time points for solution\n#One of the next two section marked with ### need to be commented out for the other one to work\n    #temporal upscaling:\n    ###\n      \n      '''\n      #p = np.random.uniform(10, 30)\n      #x0,y0,z0 = np.random.rand(3) *5\n      x0, y0, z0 = np.random.normal(loc=0, scale=10, size=3)\n      solution = solve_ivp(my_lorenz_system, t_span = t_span, y0 = [x0,y0,z0], t_eval = t_eval, args = (sigma,p,beta))\n\n      high_res_data = solution.y\n      low_res_data = downsample_data(solution.y, ds_factor)\n      '''      \n    ###\n    #changing accuracy:\n    ###\n      \n      phi = np.random.uniform(0, 2 * np.pi)\n      cos_theta = np.random.uniform(-1, 1)\n      theta = np.arccos(cos_theta)\n      r = radius  # Radius of the sphere for initial conditions\n\n      x0 = x0_center + r * np.sin(theta) * np.cos(phi)\n      y0 = y0_center + r * np.sin(theta) * np.sin(phi)\n      z0 = z0_center + r * np.cos(theta)\n       \n      solution_hr = solve_ivp(my_lorenz_system, t_span = t_span, y0 = [x0,y0,z0], t_eval = t_eval, args = (sigma,p,beta),atol=1e-2, rtol=1e-2)\n      solution_lr = solve_ivp(my_lorenz_system, t_span = t_span, y0 = [x0,y0,z0], t_eval = t_eval, args = (sigma,p,beta),atol=1e-1, rtol=1e-1)\n      high_res_data = solution_hr.y\n      low_res_data = downsample_data(solution_lr.y, ds_factor)\n      \n     ###   \n        \n        \n      data_hr.append(high_res_data)\n      data_lr.append(low_res_data)\n\n  return np.array(data_hr), np.array(data_lr)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T15:48:40.700612Z","iopub.execute_input":"2024-04-07T15:48:40.701533Z","iopub.status.idle":"2024-04-07T15:48:40.714690Z","shell.execute_reply.started":"2024-04-07T15:48:40.701490Z","shell.execute_reply":"2024-04-07T15:48:40.713632Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#training data\nnum_samples =600\ntrain_size = int(num_samples * 9/10)\n#num_samples = 400\n#train_size = int(num_samples * 4/5)\nds_factor = 1 # choose downsampling factor for temporal upscaling (2,4,...), for changing accuracy set to 1\n\nhigh_res_data, low_res_data = generating_sample_data(num_samples,ds_factor)\n\ntrain_hr, test_hr, train_lr, test_lr = train_test_split(high_res_data, low_res_data, train_size=train_size)\n\nclass LorenzDataset(Dataset):\n    def __init__(self, high_res_data, low_res_data): # initialization\n        self.high_res_data = high_res_data\n        self.low_res_data = low_res_data\n\n    def __len__(self):\n        return len(self.high_res_data)  # returns the number of time series\n\n    def __getitem__(self, idx):\n        high_res_sample = torch.tensor(self.high_res_data[idx], dtype=torch.float32)\n        low_res_sample = torch.tensor(self.low_res_data[idx], dtype=torch.float32)\n        return {'hr': high_res_sample, 'lr': low_res_sample}\n\nprint(len(high_res_data))\nprint(len(low_res_data))\n# dataset and dataloader\ntest_dataset = LorenzDataset(test_hr, test_lr)\ndataset = LorenzDataset(train_hr, train_lr)\ntest_loader = DataLoader(test_dataset, batch_size=20, shuffle = False)\ntrain_loader = DataLoader(dataset, batch_size=20, shuffle = False)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T15:48:40.716332Z","iopub.execute_input":"2024-04-07T15:48:40.716663Z","iopub.status.idle":"2024-04-07T15:48:53.142525Z","shell.execute_reply.started":"2024-04-07T15:48:40.716639Z","shell.execute_reply":"2024-04-07T15:48:53.141585Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"600\n600\n","output_type":"stream"}]},{"cell_type":"code","source":"#training\n\nchannels = 3\nnum_channels = 3\nlength_hr = high_res_data[1].shape\nsequence_length = amount_val\na = 0.1\nnum_epochs = 1000 # for temporal upscaling a lower epochs number is sufficient\nupscale_factor = ds_factor\n\ng_MSEloss_tensor = []\ng_ADVloss_tensor = []\nd_loss_tensor = []\ng_loss_tensor = []\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ngenerator = Generator_net(upscale_factor, num_blocks = 16,).to(device) # num_blocks defines the depth of the network\ndiscriminator = Discriminator(input_shape=(channels,*length_hr)).to(device)\n\n\noptimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\noptimizer_D = optim.Adam(discriminator.parameters(), lr=0.0001, betas=(0.5, 0.999))\n\n\n\nmock_input = torch.randn(1, num_channels, sequence_length).to(device)  # Adjust num_channels and sequence_length\n\nwith torch.no_grad():\n    mock_output = discriminator(mock_input)\n\n# the output shape\ndiscriminator_output_shape = mock_output.shape[1:]\n\n\nfor epoch in range(num_epochs):\n    print(\"num epoch: \", epoch)\n    for i,batch in enumerate(train_loader):\n\n        discriminator.train()\n        generator.train()\n        #print(\"batch lr: \", batch['lr'].shape)\n\n        low_res_data, high_res_data = batch['lr'].to(device), batch['hr'].to(device)\n\n        valid = torch.ones((low_res_data.size(0), *discriminator_output_shape), device=device)\n        fake = torch.zeros((low_res_data.size(0), *discriminator_output_shape), device=device)\n        # Generate data\n        #print(low_res_data.shape)\n        generated_data = generator(low_res_data)\n        #print(generated_data.shape)\n\n\n        optimizer_D.zero_grad()\n\n        loss_real = loss_function_adv(discriminator(high_res_data), valid) #tries to label real as real\n        loss_fake = loss_function_adv(discriminator(generated_data.detach()), fake) #tries to label fake as fake\n\n        output_D_real = discriminator(high_res_data)\n        output_D_fake = discriminator(generated_data.detach())\n        # print(\"r: \",output_D_real)\n        # print(\"f: \",output_D_fake)\n\n        loss_D = (loss_real + loss_fake) / 2\n        d_loss_tensor.append(loss_D.item())\n\n        #Backpropagation Discriminator\n\n        loss_D.backward()\n        optimizer_D.step()\n\n\n\n\n        # Train Generator\n\n        optimizer_G.zero_grad()\n\n        loss_gan = loss_function_adv(discriminator(generated_data), valid).to(device) #tries to fool the D. the fake is real\n        g_ADVloss_tensor.append(loss_gan.item())\n        loss_mse = loss_function_mse(generated_data, high_res_data).to(device)\n        g_MSEloss_tensor.append(loss_mse.item())\n\n        loss_G = loss_mse + a * loss_gan\n        g_loss_tensor.append(loss_G.item())\n\n        # print(\"Generator Adv Loss: {loss_gan.item()}\")\n        # print(\"Generator MSE Loss: {loss_mse.item()}\")\n        # print(\"Generator Total Loss: {loss_G.item()}\")\n\n        #Backpropagation Generator\n        loss_G.backward()\n        optimizer_G.step()\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T15:48:53.143719Z","iopub.execute_input":"2024-04-07T15:48:53.143999Z","iopub.status.idle":"2024-04-07T16:02:56.934114Z","shell.execute_reply.started":"2024-04-07T15:48:53.143974Z","shell.execute_reply":"2024-04-07T16:02:56.931616Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"num epoch:  0\nnum epoch:  1\nnum epoch:  2\nnum epoch:  3\nnum epoch:  4\nnum epoch:  5\nnum epoch:  6\nnum epoch:  7\nnum epoch:  8\nnum epoch:  9\nnum epoch:  10\nnum epoch:  11\nnum epoch:  12\nnum epoch:  13\nnum epoch:  14\nnum epoch:  15\nnum epoch:  16\nnum epoch:  17\nnum epoch:  18\nnum epoch:  19\nnum epoch:  20\nnum epoch:  21\nnum epoch:  22\nnum epoch:  23\nnum epoch:  24\nnum epoch:  25\nnum epoch:  26\nnum epoch:  27\nnum epoch:  28\nnum epoch:  29\nnum epoch:  30\nnum epoch:  31\nnum epoch:  32\nnum epoch:  33\nnum epoch:  34\nnum epoch:  35\nnum epoch:  36\nnum epoch:  37\nnum epoch:  38\nnum epoch:  39\nnum epoch:  40\nnum epoch:  41\nnum epoch:  42\nnum epoch:  43\nnum epoch:  44\nnum epoch:  45\nnum epoch:  46\nnum epoch:  47\nnum epoch:  48\nnum epoch:  49\nnum epoch:  50\nnum epoch:  51\nnum epoch:  52\nnum epoch:  53\nnum epoch:  54\nnum epoch:  55\nnum epoch:  56\nnum epoch:  57\nnum epoch:  58\nnum epoch:  59\nnum epoch:  60\nnum epoch:  61\nnum epoch:  62\nnum epoch:  63\nnum epoch:  64\nnum epoch:  65\nnum epoch:  66\nnum epoch:  67\nnum epoch:  68\nnum epoch:  69\nnum epoch:  70\nnum epoch:  71\nnum epoch:  72\nnum epoch:  73\nnum epoch:  74\nnum epoch:  75\nnum epoch:  76\nnum epoch:  77\nnum epoch:  78\nnum epoch:  79\nnum epoch:  80\nnum epoch:  81\nnum epoch:  82\nnum epoch:  83\nnum epoch:  84\nnum epoch:  85\nnum epoch:  86\nnum epoch:  87\nnum epoch:  88\nnum epoch:  89\nnum epoch:  90\nnum epoch:  91\nnum epoch:  92\nnum epoch:  93\nnum epoch:  94\nnum epoch:  95\nnum epoch:  96\nnum epoch:  97\nnum epoch:  98\nnum epoch:  99\nnum epoch:  100\nnum epoch:  101\nnum epoch:  102\nnum epoch:  103\nnum epoch:  104\nnum epoch:  105\nnum epoch:  106\nnum epoch:  107\nnum epoch:  108\nnum epoch:  109\nnum epoch:  110\nnum epoch:  111\nnum epoch:  112\nnum epoch:  113\nnum epoch:  114\nnum epoch:  115\nnum epoch:  116\nnum epoch:  117\nnum epoch:  118\nnum epoch:  119\nnum epoch:  120\nnum epoch:  121\nnum epoch:  122\nnum epoch:  123\nnum epoch:  124\nnum epoch:  125\nnum epoch:  126\nnum epoch:  127\nnum epoch:  128\nnum epoch:  129\nnum epoch:  130\nnum epoch:  131\nnum epoch:  132\nnum epoch:  133\nnum epoch:  134\nnum epoch:  135\nnum epoch:  136\nnum epoch:  137\nnum epoch:  138\nnum epoch:  139\nnum epoch:  140\nnum epoch:  141\nnum epoch:  142\nnum epoch:  143\nnum epoch:  144\nnum epoch:  145\nnum epoch:  146\nnum epoch:  147\nnum epoch:  148\nnum epoch:  149\nnum epoch:  150\nnum epoch:  151\nnum epoch:  152\nnum epoch:  153\nnum epoch:  154\nnum epoch:  155\nnum epoch:  156\nnum epoch:  157\nnum epoch:  158\nnum epoch:  159\nnum epoch:  160\nnum epoch:  161\nnum epoch:  162\nnum epoch:  163\nnum epoch:  164\nnum epoch:  165\nnum epoch:  166\nnum epoch:  167\nnum epoch:  168\nnum epoch:  169\nnum epoch:  170\nnum epoch:  171\nnum epoch:  172\nnum epoch:  173\nnum epoch:  174\nnum epoch:  175\nnum epoch:  176\nnum epoch:  177\nnum epoch:  178\nnum epoch:  179\nnum epoch:  180\nnum epoch:  181\nnum epoch:  182\nnum epoch:  183\nnum epoch:  184\nnum epoch:  185\nnum epoch:  186\nnum epoch:  187\nnum epoch:  188\nnum epoch:  189\nnum epoch:  190\nnum epoch:  191\nnum epoch:  192\nnum epoch:  193\nnum epoch:  194\nnum epoch:  195\nnum epoch:  196\nnum epoch:  197\nnum epoch:  198\nnum epoch:  199\nnum epoch:  200\nnum epoch:  201\nnum epoch:  202\nnum epoch:  203\nnum epoch:  204\nnum epoch:  205\nnum epoch:  206\nnum epoch:  207\nnum epoch:  208\nnum epoch:  209\nnum epoch:  210\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 65\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# print(\"r: \",output_D_real)\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# print(\"f: \",output_D_fake)\u001b[39;00m\n\u001b[1;32m     64\u001b[0m loss_D \u001b[38;5;241m=\u001b[39m (loss_real \u001b[38;5;241m+\u001b[39m loss_fake) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m---> 65\u001b[0m d_loss_tensor\u001b[38;5;241m.\u001b[39mappend(\u001b[43mloss_D\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m#Backpropagation Discriminator\u001b[39;00m\n\u001b[1;32m     69\u001b[0m loss_D\u001b[38;5;241m.\u001b[39mbackward()\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"\n# converting the list to tensors and changing dimensions\ng_loss_tensor = torch.tensor(g_loss_tensor)\ng_MSEloss_tensor = torch.tensor(g_MSEloss_tensor)\nprint(g_loss_tensor.shape)\nnew_dim_gLoss = g_loss_tensor.view(-1,20).mean(dim=1) #reshape, mean for every batch\nnew_dim_mseLoss = g_MSEloss_tensor.view(-1,20).mean(dim=1)\nprint(new_dim_gLoss.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T16:02:56.934967Z","iopub.status.idle":"2024-04-07T16:02:56.935336Z","shell.execute_reply.started":"2024-04-07T16:02:56.935149Z","shell.execute_reply":"2024-04-07T16:02:56.935164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_figure = plt.figure()\n\naxes = plt.axes()\nlog_g_loss = torch.log(new_dim_gLoss)\nlog_MSEloss = torch.log(new_dim_mseLoss)\n\n\naxes.plot(log_g_loss, label='Generator Total Loss', color='purple')\naxes.plot(log_MSEloss,label='Generator MSE Loss', color='green')\n\nplt.title('Training Losses')\nplt.xlabel('Epochs')\nplt.ylabel('log Loss')\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T16:02:56.937090Z","iopub.status.idle":"2024-04-07T16:02:56.937589Z","shell.execute_reply.started":"2024-04-07T16:02:56.937316Z","shell.execute_reply":"2024-04-07T16:02:56.937336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_figure = plt.figure()\n\naxes = plt.axes()\naxes.plot(g_ADVloss_tensor, label='Generator Adversarial Loss', color='red')\naxes.plot(d_loss_tensor,label='Discriminator Loss', color='blue')\nplt.title('Training Losses ')\nplt.xlabel('Batches')\nplt.ylabel('Loss')\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T16:02:56.939143Z","iopub.status.idle":"2024-04-07T16:02:56.939643Z","shell.execute_reply.started":"2024-04-07T16:02:56.939405Z","shell.execute_reply":"2024-04-07T16:02:56.939425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot for a sample super-resolution trajectory\n\nsample_test_lr = test_dataset[10]['lr'].unsqueeze(0)\nwith torch.no_grad():\n    generated_data = generator(sample_test_lr.to(device))\n\ngenerated_data_np = generated_data.detach().cpu().numpy()\n#print(generated_data_np)\nx_sr = generated_data_np[0,0,:]\ny_sr = generated_data_np[0,1,:]\nz_sr = generated_data_np[0,2,:]\n\na = 5\nfig = plt.figure(facecolor='w', figsize=(6.4*a, 4.8*a)) #creates figure\n\naxes = plt.axes(projection=\"3d\") # 3d plot area for 3d data\naxes.set_facecolor('w')\naxes.plot(x_sr,y_sr,z_sr,'black', linewidth=0.8)\naxes.scatter3D(x_sr, y_sr, z_sr, c=z_sr, cmap='ocean', s = 8)\n\nplt.grid(False)\nplt.axis('off')\nplt.title('Lorenz generated',color='white', fontsize=10*a)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T16:02:56.942087Z","iopub.status.idle":"2024-04-07T16:02:56.942596Z","shell.execute_reply.started":"2024-04-07T16:02:56.942323Z","shell.execute_reply":"2024-04-07T16:02:56.942341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot for a sample low-resolution trajectory\nsample_test_lr = test_dataset[10]['lr']\n#print(sample_test_lr)\nsample_test_lr_np = sample_test_lr.detach().cpu().numpy()\nx_lr = sample_test_lr_np[0,:]\ny_lr = sample_test_lr_np[1,:]\nz_lr = sample_test_lr_np[2,:]\n\na = 5\nfig = plt.figure(facecolor='w', figsize=(6.4*a, 4.8*a)) #creates figure\n\naxes = plt.axes(projection=\"3d\") # 3d plot area for 3d data\naxes.set_facecolor('w')\naxes.plot(x_lr,y_lr,z_lr,'black', linewidth=0.8)\naxes.scatter3D(x_lr, y_lr, z_lr, c=z_lr, cmap='ocean', s = 8)\n\nplt.grid(False)\nplt.axis('off')\nplt.title('Lorenz low resolution',color='white', fontsize=10*a)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T16:02:56.943837Z","iopub.status.idle":"2024-04-07T16:02:56.944272Z","shell.execute_reply.started":"2024-04-07T16:02:56.944044Z","shell.execute_reply":"2024-04-07T16:02:56.944063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot for a sample high-resolution trajectory\nsample_test_hr = test_dataset[10]['hr']\n#print(sample_test_lr)\nsample_test_hr_np = sample_test_hr.detach().cpu().numpy()\nx_hr = sample_test_hr_np[0,:]\ny_hr = sample_test_hr_np[1,:]\nz_hr = sample_test_hr_np[2,:]\n\na = 5\nfig = plt.figure(facecolor='w', figsize=(6.4*a, 4.8*a)) #creates figure\n\naxes = plt.axes(projection=\"3d\") # 3d plot area for 3d data\naxes.set_facecolor('w')\naxes.plot(x_hr,y_hr,z_hr,'black', linewidth=0.8)\naxes.scatter3D(x_hr, y_hr, z_hr, c=z_hr, cmap='ocean', s = 8)\n\nplt.grid(False)\nplt.axis('off')\nplt.title('Lorenz high resolution',color='white', fontsize=10*a)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T16:02:56.945831Z","iopub.status.idle":"2024-04-07T16:02:56.946281Z","shell.execute_reply.started":"2024-04-07T16:02:56.946055Z","shell.execute_reply":"2024-04-07T16:02:56.946073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"''' Calculation of MSE and relative distance\nFor temporal upscaling the calulations between the low resolution and high resolution data needs to be commented out\nbecause they have a different amount of timesteps'''\nmse_values = []\nmse_values_lr_hr = []\nrelative_difference_values = []\nrelative_difference_values2 = []\nabs_diff_values = []\nabs_diff_values2 = []\nfor batch in test_loader:\n    lr_test = batch['lr']  # Low resolution  data\n    hr_test = batch['hr']  # Corresponding high resolution data\n    \n    hr_test_tensor = torch.tensor(hr_test,dtype=torch.float32)\n    lr_test_tensor = torch.tensor(lr_test,dtype=torch.float32)\n    # Generate sr\n    with torch.no_grad():\n        sr_test = generator(lr_test.to(device))\n\n\n\n    sr_test_tensor = sr_test.detach().cpu()    # print(len(test_dataset))\n    # print(sr_test_tensor.shape)\n\n    # Calculates MSE for each pair of SR and HR in  batch\n    for sr, hr in zip(sr_test_tensor, hr_test_tensor):\n        #print(hr.shape)\n        mse = loss_function_mse(sr, hr)\n        mse_values.append(mse.item())\n    #'''\n    # Calculates MSE for each pair of LR and HR in  batch\n    for lr, hr in zip(lr_test_tensor, hr_test_tensor):\n        #print(hr.shape)\n        mse2 = loss_function_mse(lr,hr)\n        mse_values_lr_hr.append(mse2.item())\n    #'''\n\n    max_value = torch.max(hr_test_tensor).item()\n    # Calculates relative distance for each pair of SR and HR in  batch\n    for sr, hr in zip(sr_test_tensor, hr_test_tensor):\n          #print(hr.shape)\n          abs_diff = loss_L1(sr, hr)\n          abs_diff_values.append(abs_diff.item())\n          relative_difference = abs_diff.item() / max_value\n          relative_difference_values.append(relative_difference)\n    #'''\n    # Calculates relative distance for each pair of LR and HR in  batch\n    for lr, hr in zip(lr_test_tensor, hr_test_tensor):\n        #print(hr.shape)\n        abs_diff2 = loss_L1(lr, hr)\n        abs_diff_values2.append(abs_diff2.item())\n        relative_difference2 = abs_diff2.item() / max_value\n        relative_difference_values2.append(relative_difference2)\n    #'''\n        \n#print(mse_values)\n\nmse_average = sum(mse_values) / len(mse_values)\nmse2_average = sum(mse_values_lr_hr) / len(mse_values_lr_hr)\nabs_diff_avg_sr = sum(abs_diff_values) / len(abs_diff_values)\nabs_diff_avg_lr = sum(abs_diff_values2) / len(abs_diff_values2)\nprint(f\"Average MSE sr,hr: {mse_average}\")\nprint(f\"Average MSE lr,hr: {mse2_average}\")\ndiff_average_sr = sum(relative_difference_values) / len(relative_difference_values)\ndiff_average_lr = sum(relative_difference_values2) / len(relative_difference_values2)\nprint(\" relative sr:\", diff_average_sr)\nprint(\"relative lr:\", diff_average_lr)\nprint(\"abs difference sr: \", abs_diff_avg_sr)\nprint(\"abs difference lr: \", abs_diff_avg_lr)\n\n\n\nplt.title(\"relative distance\")\nplt.xlabel(\"test set\")\nplt.ylabel(\"relative distance\")\nplt.yscale(\"log\")\n#plt.plot(mse_values, label=\"hr-sr\")\n#plt.plot(mse_values_lr_hr, label=\"hr-lr\")\nplt.plot(relative_difference_values, label =\"Relative difference HR-SR\")\nplt.plot(relative_difference_values2, label = \"Relative difference HR-LR\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T16:02:56.948040Z","iopub.status.idle":"2024-04-07T16:02:56.948450Z","shell.execute_reply.started":"2024-04-07T16:02:56.948221Z","shell.execute_reply":"2024-04-07T16:02:56.948240Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#1D representation\nplt.figure(figsize=(9, 4))\n\nplt.xlabel(\"time\")\nplt.ylabel(\"x\")\n\ntime = np.linspace(0, 7, 800)\nplt.plot(time,x_lr,  'cyan', label='Low Resolution')\nplt.plot(time,x_hr, 'magenta', label='High Resolution')\nplt.plot(time,x_sr, 'green', label='Super Resolution')\nplt.legend()\n#plt.gca().set_facecolor('white')\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T16:02:56.949567Z","iopub.status.idle":"2024-04-07T16:02:56.949884Z","shell.execute_reply.started":"2024-04-07T16:02:56.949726Z","shell.execute_reply":"2024-04-07T16:02:56.949739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(9, 4))\n\nplt.xlabel(\"time\")\nplt.ylabel(\"y\")\n\n\nplt.plot(time,y_lr, 'cyan', label='Low Resolution')\nplt.plot(time,y_hr, 'magenta', label='High Resolution')\nplt.plot(time,y_sr, 'green', label='Super Resolution')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T16:02:56.951587Z","iopub.status.idle":"2024-04-07T16:02:56.951927Z","shell.execute_reply.started":"2024-04-07T16:02:56.951760Z","shell.execute_reply":"2024-04-07T16:02:56.951775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(9, 4))\n\nplt.xlabel(\"time\")\nplt.ylabel(\"z\")\n\n\nplt.plot(time,z_lr, 'cyan', label='Low Resolution')\nplt.plot(time,z_hr, 'magenta', label='High Resolution')\nplt.plot(time,z_sr, 'green', label='Super Resolution')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T16:02:56.953244Z","iopub.status.idle":"2024-04-07T16:02:56.953590Z","shell.execute_reply.started":"2024-04-07T16:02:56.953429Z","shell.execute_reply":"2024-04-07T16:02:56.953443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def my_lorenz_system(t,vec,sigma,p,beta):\n  x,y,z = vec\n  dxdt = sigma*(y-x)\n  dydt = x*(p-z)-y\n  dzdt = x*y-beta*z\n  return dxdt,dydt,dzdt\n\n#initial conditions\n\n\nx0 = 2\ny0 = 3\nz0 = -14\n\n\n#x0,y0,z0 = 0.9927168, 0.9545199, 0.8107614\n\nx00 = x0 #+ 1e-9\ny00 = y0 +0.001 #+ 1e-9\nz00 = z0 #+ 1e-9\n#x0, y0, z0 = np.random.normal(loc=1, scale=10, size=3)\nprint(x0, y0, z0)\n#parameters\nsigma = 10\nbeta = 8/3\np = 28\n\nt_span = (0,16)\n\nt_eval = np.linspace(t_span[0], t_span[1], 800) #array of time points for solution\n\n#high resolution trajectories\nsol_hr = solve_ivp(my_lorenz_system, t_span = t_span, y0 = [x0,y0,z0], t_eval = t_eval, args = (sigma,p,beta),atol=1e-4, rtol=1e-4)\nsol_hr2 = solve_ivp(my_lorenz_system, t_span = t_span, y0 = [x00,y00,z00], t_eval = t_eval, args = (sigma,p,beta),atol=1e-4, rtol=1e-4)\n\n#low resolution trajectories\nsol_lr = solve_ivp(my_lorenz_system, t_span = t_span, y0 = [x0,y0,z0], t_eval = t_eval, args = (sigma,p,beta),atol=1e-2, rtol=1e-2)\nsol_lr2 = solve_ivp(my_lorenz_system, t_span = t_span, y0 = [x00,y00,z00], t_eval = t_eval, args = (sigma,p,beta),atol=1e-2, rtol=1e-2)\n\nwith torch.no_grad():\n    sol_lr_tensor = torch.tensor(sol_lr.y, dtype=torch.float32).unsqueeze(0).to(device)  \n    sol_lr2_tensor = torch.tensor(sol_lr2.y, dtype=torch.float32).unsqueeze(0).to(device) \n\n    # Generate hr solutions\n    sol_sr = generator(sol_lr_tensor)\n    sol_sr2 = generator(sol_lr2_tensor)\n\nsol_sr_np = sol_sr.detach().cpu().numpy()\nsol_sr2_np = sol_sr2.detach().cpu().numpy()\n\nprint(sol_sr.shape)\nsolution = sol_hr.y\nprint(solution.shape)\nx1 = solution[0,:]\ny1 = solution[1,:]\nz1 = solution[2,:]\n\nsolution2 = sol_hr2.y\nx2 = solution2[0,:]\ny2 = solution2[1,:]\nz2 = solution2[2,:]\n\nsolution3 = sol_lr.y\nx3 = solution3[0,:]\ny3 = solution3[1,:]\nz3 = solution3[2,:]\n\nsolution4 = sol_lr2.y\nx4 = solution4[0,:]\ny4 = solution4[1,:]\nz4 = solution4[2,:]\n\nsolution_sr = sol_sr_np\nprint(solution_sr.shape)\nx5 = solution_sr[0,0,:]\ny5 = solution_sr[0,1,:]\nz5 = solution_sr[0,2,:]\n\nsolution_sr2 = sol_sr2_np\nx6 = solution_sr2[0,0,:]\ny6 = solution_sr2[0,1,:]\nz6 = solution_sr2[0,2,:]\nprint(solution_sr2.shape)\n\ninit_distance =np.sqrt((x2[0]-x1[0])**2+(y2[0]-y1[0])**2+(z2[0]-z1[0])**2)\nprint(init_distance)\ndistance_hr = np.sqrt((x1-x2)**2+(y1-y2)**2+(z1-z2)**2)\ndistance_lr = np.sqrt((x3-x4)**2+(y3-y4)**2+(z3-z4)**2)\ndistance_sr = np.sqrt((x5-x6)**2+(y5-y6)**2+(z5-z6)**2)\ninit_distance_sr = np.sqrt((x6[0]-x5[0])**2+(y6[0]-y5[0])**2+(z6[0]-z5[0])**2)\nprint(\"distance between initial points sr trajectories: \",init_distance_sr)\naverage_distance = sum(distance_sr) / len(distance_sr)\nprint(\"average difference\", average_distance)\ndistance_hr[distance_hr == 0] = 1e-10\ndistance_lr[distance_lr == 0] = 1e-10\ndistance_sr[distance_sr == 0] = 1e-10\n\ntime = t_eval\n\nlyapunov = init_distance * np.exp(0.9056 * time)\n\nplt.figure()\nplt.yscale(\"log\")\nplt.plot(time,distance_sr, label=\"Distance SR\")\nplt.plot(time,distance_hr, label=\"Distance HR\")\nplt.plot(time,distance_lr, label=\"Distance LR\")\nplt.plot(time,lyapunov, label=\"Lyaponov exponent\")\nplt.xlabel(\"time\")\nplt.ylabel(\"absolute distance\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T16:02:56.955359Z","iopub.status.idle":"2024-04-07T16:02:56.955735Z","shell.execute_reply.started":"2024-04-07T16:02:56.955573Z","shell.execute_reply":"2024-04-07T16:02:56.955587Z"},"trusted":true},"execution_count":null,"outputs":[]}]}